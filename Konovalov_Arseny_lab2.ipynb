{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FooolyHARD/ognp-sia-lab2-ml/blob/main/Konovalov_Arseny_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs6Yt1h1pO-0"
      },
      "source": [
        "В данной лабораторной работе будут показаны основы анализа текстовой информации. В ходе её выполнения мы познакомимся с этапами предварительной подготовки данных, а также применим машинное обучение для задачи классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiY7HEwBA5ht"
      },
      "source": [
        "Будем использовать датасет с текстами песен разных жанров: https://www.kaggle.com/mehedihasan9021/movie-script-dataset\n",
        "\n",
        "\n",
        "> Задание выполняется в google colab. Чтобы редактировать ноутбук, не забудьте сохранить его копию на диске. Скачайте файл по ссылке, загрузите в сессионное хранилище и запускайте ячейки с кодом, следуя инструкциям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqSLYPq4XoXH"
      },
      "source": [
        "Читаем набор данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9OwJhjSnzjp"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NwVymy9wMHSF",
        "outputId": "0b7b3189-17c6-4464-c8f8-6fc63a33217b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>SongInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>CASTING CROWNS - WHO AM I LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>GLORY REVEALED - BY HIS WOUNDS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>CAEDMON'S CALL - GOD OF WONDERS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>MERCYME - I CAN ONLY IMAGINE LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>AARON SHUST - MY SAVIOR MY GOD LYRICS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       genre  ...                                SongInfo\n",
              "0  Christian  ...        CASTING CROWNS - WHO AM I LYRICS\n",
              "1  Christian  ...   GLORY REVEALED - BY HIS WOUNDS LYRICS\n",
              "2  Christian  ...  CAEDMON'S CALL - GOD OF WONDERS LYRICS\n",
              "3  Christian  ...     MERCYME - I CAN ONLY IMAGINE LYRICS\n",
              "4  Christian  ...   AARON SHUST - MY SAVIOR MY GOD LYRICS\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpByjtHQMASx",
        "outputId": "9d7a8418-680f-442a-d5a3-f5cb1e9eb7b9"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 558 entries, 0 to 557\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   genre     558 non-null    object\n",
            " 1   lyrics    558 non-null    object\n",
            " 2   SongInfo  558 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 13.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxP-iGu-MCi4"
      },
      "source": [
        "columns = data[['genre', 'lyrics']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bYF8acQSM6zE",
        "outputId": "7994f824-5512-49c6-d260-212735830e32"
      },
      "source": [
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Ha I dont care ha, about your past I just wan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Hoverin by my suitcase  Tryin to find a warm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>I dont know why I love you like I do  After a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>C. C. Rider Elvis Presley  Well now see., C. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Cynthia get up and dance to the music!  Get o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>558 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre                                             lyrics\n",
              "0    Christian   Who am I, that the Lord of all the earth Woul...\n",
              "1    Christian   Glory Revealed  By His Wounds He was pierced ...\n",
              "2    Christian   Lord of heaven and earth Lord of all creation...\n",
              "3    Christian   I can only imagine what it will be like When ...\n",
              "4    Christian   I am not skilled to understand What God has w...\n",
              "..         ...                                                ...\n",
              "553        R&B   Ha I dont care ha, about your past I just wan...\n",
              "554        R&B   Hoverin by my suitcase  Tryin to find a warm ...\n",
              "555        R&B   I dont know why I love you like I do  After a...\n",
              "556        R&B   C. C. Rider Elvis Presley  Well now see., C. ...\n",
              "557        R&B   Cynthia get up and dance to the music!  Get o...\n",
              "\n",
              "[558 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM6VU_qPXvId"
      },
      "source": [
        "Посмотрим какие жанры присутствуют в датасете. Для этого выведем уникальные значения столбца:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgU-qG2iM74F",
        "outputId": "7e560987-3640-4ceb-a420-f8862765d5df"
      },
      "source": [
        "columns['genre'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Christian', 'Country', 'Hip-Hop', 'Pop', 'Rock', 'R&B'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De2qmchpX2-a"
      },
      "source": [
        "Посчитаем также сколько песен каждого жанра представлено:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQotoiKyOMwl",
        "outputId": "bb767949-0411-4361-a720-0db3b53ff18f"
      },
      "source": [
        "columns['genre'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pop          100\n",
              "Rock          95\n",
              "Christian     94\n",
              "Hip-Hop       91\n",
              "R&B           91\n",
              "Country       87\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSGSPwtzxlyA"
      },
      "source": [
        "Оставляем только 2 жанра, которые планируем отличать друг от друга. Для примера будут использованы Christian и Hip-Hop, позднее в формулировке задания нужно будет сгенерировать собственную пару жанров. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC3pzAFS1ofC"
      },
      "source": [
        "columns = columns[(columns.genre == 'Christian') | (columns.genre == 'Hip-Hop')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aT2_kEVY2dw"
      },
      "source": [
        "###Предварительная обработка текстовых данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4il3oZFY_Kw"
      },
      "source": [
        "Для того, чтобы применять текстовые данные для обучения той или иной модели машинного обучения, их нужно привести в подходящий для этого вид. В этом нам помогут следующие шаги предварительной подготовки:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfTWe_1oCrsd"
      },
      "source": [
        "####Приведение к нижнему регистру"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2GZxS6PZkcx"
      },
      "source": [
        "Так как слова (например) \"Beer\" и \"beer\" будут считаться разными словами из-за разницы в регистре буквы b, а первая буква предложения, как правило, является заглавной, важно привести все слова предложения к нижнему регистру. Таким образом, \"beer\", встретившееся в начале предложения и в его середине, будут распознаны как одно слово."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq9MqtqoW2ce"
      },
      "source": [
        "lowered = columns['lyrics'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYUruNhrCFjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35dc73b9-b239-4b5a-d5ab-4596d14f83ff"
      },
      "source": [
        "columns['lowered'] = lowered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4YULmIC9oZ"
      },
      "source": [
        "####Токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZZIXNXebXvi"
      },
      "source": [
        "Имеющиеся тексты нужно разбить на отдельные слова. Такой процесс называется ***токенизация***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ws0-pYLCpI5",
        "outputId": "d2ea19cb-f4fd-43dc-a251-208d77b5dc87"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxi9nYbMDGWa"
      },
      "source": [
        "tokened = columns.apply(lambda row: nltk.word_tokenize(row['lowered']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqSXoypQDNE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7e7da9-1d3f-4c2e-aab2-a04761367b1d"
      },
      "source": [
        "columns['tokened'] = tokened"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOISss1fGOtf"
      },
      "source": [
        "####Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo0gIbfamIqr"
      },
      "source": [
        "***Стоп-словами*** называются распространённые слова, не несущие особой смысловой нагрузки, а значит никак не помогающие в последующей задаче классификации. Такие слова мы считаем шумом, и, соответственно, удаляем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKUN9izHnQfR"
      },
      "source": [
        "Существует специальный корпус стоп-слов на разных языках. Так как сейчас мы имеем дело с текстами на английском языке, выведем стоп-слова для английского:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKkAzYAeDbhN",
        "outputId": "d52210ec-2563-43ca-af58-de9193d5ac4b"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43f5-hujGW7l"
      },
      "source": [
        "noise = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YFPt0YxGf9J"
      },
      "source": [
        "withoutstop = columns['tokened'].apply(lambda x: [item for item in x if item not in noise])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvUp4qWzGlMr"
      },
      "source": [
        "without_stop = []\n",
        "for a in withoutstop:    \n",
        "    without_stop.append(\", \".join(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLJ1ezBGnoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e44bc9-8cd1-4677-b5f9-5c8e03b2744c"
      },
      "source": [
        "columns['without_stop'] = without_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWIlOfFOPId-"
      },
      "source": [
        "####Лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNsgTkFPOjX"
      },
      "source": [
        "У одного и того же слова бывают разные формы. Например, dances - форма слова dance. Лемматизация - это приведение к ***лемме*** - исходной форме слова. Её также необходимо применить к нашим данным, чтобы разные формы слова не считались за отдельные слова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KA2A_wgUUfW"
      },
      "source": [
        "Существует целый ряд лемматизаторов, которые показывают себя с разной эффективностью на разных языках. Для работы с английским языком эффективен **WordNetLemmatizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR5Lr4WzGt5Q",
        "outputId": "3dcf384a-f753-4ccf-a74c-8369337d1c13"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i7WLP9-Z0_L",
        "outputId": "c26a1617-bb3a-4d23-d364-7d407781977e"
      },
      "source": [
        "print(lemmatizer.lemmatize(\"dances\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcmk4VWvb7Mq"
      },
      "source": [
        "lemmatized = columns['without_stop'].apply(lambda x: [lemmatizer.lemmatize(x)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puuud0HJdJRy"
      },
      "source": [
        "lemma = []\n",
        "for a in lemmatized:    \n",
        "    lemma.append(\", \".join(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTLDzaHFdMMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d038aca-46cb-49fa-f22d-cd970b5e91d1"
      },
      "source": [
        "columns['lemmatized'] = lemma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkfqMYftynRV"
      },
      "source": [
        "Таким образом, на каждом этапе мы добавляли столбец с той или иной модификацией, чтобы получить пригодные для обучения данные. Посмотрим на датафрейм, который получился:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "ixDtw5yEyklr",
        "outputId": "3f202a57-4bdc-4240-c788-b9495b6c6d3d"
      },
      "source": [
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>lowered</th>\n",
              "      <th>tokened</th>\n",
              "      <th>without_stop</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>who am i, that the lord of all the earth woul...</td>\n",
              "      <td>[who, am, i, ,, that, the, lord, of, all, the,...</td>\n",
              "      <td>,, lord, earth, would, care, know, name, would...</td>\n",
              "      <td>,, lord, earth, would, care, know, name, would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>glory revealed  by his wounds he was pierced ...</td>\n",
              "      <td>[glory, revealed, by, his, wounds, he, was, pi...</td>\n",
              "      <td>glory, revealed, wounds, pierced, transgressio...</td>\n",
              "      <td>glory, revealed, wounds, pierced, transgressio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>lord of heaven and earth lord of all creation...</td>\n",
              "      <td>[lord, of, heaven, and, earth, lord, of, all, ...</td>\n",
              "      <td>lord, heaven, earth, lord, creation, lord, hea...</td>\n",
              "      <td>lord, heaven, earth, lord, creation, lord, hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>i can only imagine what it will be like when ...</td>\n",
              "      <td>[i, can, only, imagine, what, it, will, be, li...</td>\n",
              "      <td>imagine, like, walk, side, imagine, eyes, see,...</td>\n",
              "      <td>imagine, like, walk, side, imagine, eyes, see,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>i am not skilled to understand what god has w...</td>\n",
              "      <td>[i, am, not, skilled, to, understand, what, go...</td>\n",
              "      <td>skilled, understand, god, willed, ,, god, plan...</td>\n",
              "      <td>skilled, understand, god, willed, ,, god, plan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Dirty dog Im, Im a dirty dog Im a dirty dog I...</td>\n",
              "      <td>dirty dog im, im a dirty dog im a dirty dog i...</td>\n",
              "      <td>[dirty, dog, im, ,, im, a, dirty, dog, im, a, ...</td>\n",
              "      <td>dirty, dog, im, ,, im, dirty, dog, im, dirty, ...</td>\n",
              "      <td>dirty, dog, im, ,, im, dirty, dog, im, dirty, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Regulators, we regulate any stealing of his p...</td>\n",
              "      <td>regulators, we regulate any stealing of his p...</td>\n",
              "      <td>[regulators, ,, we, regulate, any, stealing, o...</td>\n",
              "      <td>regulators, ,, regulate, stealing, property, d...</td>\n",
              "      <td>regulators, ,, regulate, stealing, property, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Have you ever met a girl that you tried to da...</td>\n",
              "      <td>have you ever met a girl that you tried to da...</td>\n",
              "      <td>[have, you, ever, met, a, girl, that, you, tri...</td>\n",
              "      <td>ever, met, girl, tried, date, year, make, love...</td>\n",
              "      <td>ever, met, girl, tried, date, year, make, love...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Yo, yo, yo They wanna know  Whos that girl? (...</td>\n",
              "      <td>yo, yo, yo they wanna know  whos that girl? (...</td>\n",
              "      <td>[yo, ,, yo, ,, yo, they, wan, na, know, whos, ...</td>\n",
              "      <td>yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...</td>\n",
              "      <td>yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>3 6 9, damn shes fine Hopin she can sock it t...</td>\n",
              "      <td>3 6 9, damn shes fine hopin she can sock it t...</td>\n",
              "      <td>[3, 6, 9, ,, damn, shes, fine, hopin, she, can...</td>\n",
              "      <td>3, 6, 9, ,, damn, shes, fine, hopin, sock, one...</td>\n",
              "      <td>3, 6, 9, ,, damn, shes, fine, hopin, sock, one...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>185 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre  ...                                         lemmatized\n",
              "0    Christian  ...  ,, lord, earth, would, care, know, name, would...\n",
              "1    Christian  ...  glory, revealed, wounds, pierced, transgressio...\n",
              "2    Christian  ...  lord, heaven, earth, lord, creation, lord, hea...\n",
              "3    Christian  ...  imagine, like, walk, side, imagine, eyes, see,...\n",
              "4    Christian  ...  skilled, understand, god, willed, ,, god, plan...\n",
              "..         ...  ...                                                ...\n",
              "267    Hip-Hop  ...  dirty, dog, im, ,, im, dirty, dog, im, dirty, ...\n",
              "268    Hip-Hop  ...  regulators, ,, regulate, stealing, property, d...\n",
              "269    Hip-Hop  ...  ever, met, girl, tried, date, year, make, love...\n",
              "270    Hip-Hop  ...  yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...\n",
              "271    Hip-Hop  ...  3, 6, 9, ,, damn, shes, fine, hopin, sock, one...\n",
              "\n",
              "[185 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fTc3speuRU_"
      },
      "source": [
        "####Разделим данные на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slicW92xunS6"
      },
      "source": [
        "x_train - тексты, на которых мы обучаем модель. В данном случае мы используем столбец lemmatized, так как он содержит данные, прошедшие все этапы подготовки \n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "y_train - жанры, соответствующие текстам, на которых модель обучается - столбец genre\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "x_test - точно такие же тексты из набора данных, на которых мы будем проверять, насколько модель научилась предсказывать жанр\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "y_test - жанры, соответствующие x_test. т.е. мы смотрим, насколько предсказания соответствуют содержимому этой переменной, чтобы оценить качество обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNflRzghthgt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split(columns.lemmatized, columns.genre, train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUGVD0A2uWHs",
        "outputId": "1bb088ec-f3d0-4da0-cb44-f1c5b9ae1396"
      },
      "source": [
        "columns.genre.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Christian    94\n",
              "Hip-Hop      91\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvUGd5D45Lvg"
      },
      "source": [
        "####Векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOZdvHTa8y3U"
      },
      "source": [
        "Следующий этап - ***векторизация***, то есть представление текста в численном виде, чтобы закодированные данные в дальнейшем использовать на модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APRGsKZx5JVu"
      },
      "source": [
        "Иногда помимо отдельных слов для улучшения качества обучения будет полезно использовать также комбинации из 2-3 слов. Здесь мы используем векторизатор CountVectorizer, который имеет встроенный метод - мешок n-грамм.\n",
        "\n",
        "> n = 1 - униграмма (для обучения используются слова по отдельности)\n",
        "\n",
        "> n = 2 - биграмма (для обучения используются пары слов)\n",
        "\n",
        "> n = 3 - триграмма (для обучения используются тройки слов)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Qsuu8F24RX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9eEKTEP-R_6"
      },
      "source": [
        "Задаём для векторизатора ngram_range=(1, 3), то есть используем все варианты n от 1 до 3 и прибегаем как к униграммам, так и к биграммам и триграммам:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-7CcA8d24Dd"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9m6sTC0-lmB"
      },
      "source": [
        "### Классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9TxA5ek-vvi"
      },
      "source": [
        "Для задачи классификации используем Наивный Байесовский Классификатор - простой вероятностный классификатор, основанный на применении теоремы Байеса со строгими предположениями о независимости. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Qo0JJPvzO7"
      },
      "source": [
        "#импортируем байесовский классификатор\n",
        "from sklearn.naive_bayes import MultinomialNB "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "dOJS1mskyLnf",
        "outputId": "bbed1c7b-5f54-4728-ad05-5eb2af837422"
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5ba15811582f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# тестовую выборку просто векторизировали\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectorized_x_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUW3yo_FyLcr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZ_Yn7j42JB"
      },
      "source": [
        "Посмотрим предсказания для тестовой выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwjjKPF64zTQ",
        "outputId": "c07a2ad5-3ab6-4ba2-fc9e-7ed718f75dc6"
      },
      "source": [
        "clf.predict(vectorized_x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Christian', 'Christian',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Hip-Hop', 'Christian',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop', 'Hip-Hop',\n",
              "       'Hip-Hop', 'Christian', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop',\n",
              "       'Christian', 'Christian', 'Hip-Hop', 'Christian', 'Christian',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop',\n",
              "       'Christian', 'Hip-Hop', 'Hip-Hop', 'Christian', 'Hip-Hop',\n",
              "       'Hip-Hop'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2sNKSRk46ao"
      },
      "source": [
        "Получим оценки классификации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W1R9x6J3GVS",
        "outputId": "6d991554-cbcb-43a2-ded6-83e80e5935fd"
      },
      "source": [
        "from sklearn.metrics import * \n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Christian       0.93      0.96      0.95        28\n",
            "     Hip-Hop       0.96      0.93      0.95        28\n",
            "\n",
            "    accuracy                           0.95        56\n",
            "   macro avg       0.95      0.95      0.95        56\n",
            "weighted avg       0.95      0.95      0.95        56\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gxRZ_lI-4Da"
      },
      "source": [
        "###Задание"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.metrics import * "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2n8MkiOdRR7",
        "outputId": "e0426b76-ec76-4fee-832e-3c6ae2878102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1**\n",
        "\n",
        "ваши жанры ***Pop*** и ***Christian*** "
      ],
      "metadata": {
        "id": "1KMoiscIduuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"dataset.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gnnmiSLleXyR",
        "outputId": "5a592659-ad8d-4336-b488-42cb682d76d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       genre                                             lyrics  \\\n",
              "0  Christian   Who am I, that the Lord of all the earth Woul...   \n",
              "1  Christian   Glory Revealed  By His Wounds He was pierced ...   \n",
              "2  Christian   Lord of heaven and earth Lord of all creation...   \n",
              "3  Christian   I can only imagine what it will be like When ...   \n",
              "4  Christian   I am not skilled to understand What God has w...   \n",
              "\n",
              "                                 SongInfo  \n",
              "0        CASTING CROWNS - WHO AM I LYRICS  \n",
              "1   GLORY REVEALED - BY HIS WOUNDS LYRICS  \n",
              "2  CAEDMON'S CALL - GOD OF WONDERS LYRICS  \n",
              "3     MERCYME - I CAN ONLY IMAGINE LYRICS  \n",
              "4   AARON SHUST - MY SAVIOR MY GOD LYRICS  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-345b4280-eeed-4dca-b04d-10a3be6923fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>SongInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>CASTING CROWNS - WHO AM I LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>GLORY REVEALED - BY HIS WOUNDS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>CAEDMON'S CALL - GOD OF WONDERS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>MERCYME - I CAN ONLY IMAGINE LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>AARON SHUST - MY SAVIOR MY GOD LYRICS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-345b4280-eeed-4dca-b04d-10a3be6923fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-345b4280-eeed-4dca-b04d-10a3be6923fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-345b4280-eeed-4dca-b04d-10a3be6923fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dropped other genres\n",
        "columns = data[['genre', 'lyrics']]\n",
        "columns = columns[(columns.genre == 'Christian') | (columns.genre == 'Pop')]\n",
        "print(columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oymg2H2mfS20",
        "outputId": "0e8e1050-d821-478b-f7b9-33ef9809fa72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         genre                                             lyrics\n",
            "0    Christian   Who am I, that the Lord of all the earth Woul...\n",
            "1    Christian   Glory Revealed  By His Wounds He was pierced ...\n",
            "2    Christian   Lord of heaven and earth Lord of all creation...\n",
            "3    Christian   I can only imagine what it will be like When ...\n",
            "4    Christian   I am not skilled to understand What God has w...\n",
            "..         ...                                                ...\n",
            "367        Pop   Have you ever met a girl that you tried to da...\n",
            "368        Pop   Im outta luck, outta love Gotta photograph, p...\n",
            "369        Pop   She was a fast machine  She kept her motor cl...\n",
            "370        Pop   Good times, these are the good times Leave yo...\n",
            "371        Pop   All the small things True care, truth brings ...\n",
            "\n",
            "[194 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preparation of text\n",
        "columns['lyrics'] = columns['lyrics'].str.lower()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "noise = set(stopwords.words('english'))\n",
        "punct = set(string.punctuation)"
      ],
      "metadata": {
        "id": "eoqqR_a8gK9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def go2token(data):\n",
        "    tokens = [ch for ch in word_tokenize(data) if ch not in noise and ch not in punct]\n",
        "    return ', '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
        "tokened = columns.apply(lambda row: go2token(row['lyrics']), axis=1)\n",
        "without_stop = []\n",
        "for a in tokened:    \n",
        "    without_stop.append(a)\n",
        "columns['lyrics'] = without_stop"
      ],
      "metadata": {
        "id": "Xwi73HKIgWkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(columns.lyrics, columns.genre, train_size = 0.7)\n",
        "columns.genre.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qejnEKP5gpRH",
        "outputId": "ab4fe76f-782e-4162-f0d9-5ff43f7ceaaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pop          100\n",
              "Christian     94\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Vectiorization and learning etc\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)\n",
        "vectorized_x_test = vectorizer.transform(x_test)\n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjOvZA-xgwNT",
        "outputId": "7bbe1b7c-969a-4b72-a24e-6a0cd771eb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Christian       0.97      0.91      0.94        34\n",
            "         Pop       0.89      0.96      0.92        25\n",
            "\n",
            "    accuracy                           0.93        59\n",
            "   macro avg       0.93      0.94      0.93        59\n",
            "weighted avg       0.93      0.93      0.93        59\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Genre definer\n",
        "def genre_def(data):\n",
        "  data = data.lower()\n",
        "  data = go2token(data)\n",
        "  vectorized_data_test = vectorizer.transform([data])\n",
        "  print(clf.predict(vectorized_data_test))"
      ],
      "metadata": {
        "id": "Wus04HkIhCEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Задание*** ***2***"
      ],
      "metadata": {
        "id": "EXRb9vO3Gb7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reading files\n",
        "with open('Billie Jean.txt', 'r') as file:\n",
        "    Pop_inline = file.read().replace('\\n', '')\n",
        "with open('Graves into Garden.txt', 'r') as file:\n",
        "    Christian_inline = file.read().replace('\\n', '')\n",
        "print(Pop_inline)\n",
        "print(Christian_inline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgzFcyOdGbn8",
        "outputId": "f3b12ad2-c703-42cf-f6be-80feff829bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She was more like a beauty queenFrom a movie sceneI said, \"Don't mind, but what do you meanI am the oneWho will dance on the floor in the round?\"She said I am the oneWho will dance on the floor in the roundShe told me her name was Billie JeanAs she caused a sceneThen every head turned with eyes that dreamed of being the oneWho will dance on the floor in the roundPeople always told me, \"Be careful of what you do.And don't go around breaking young girls' hearts.\"And mother always told me, \"A-be careful of who you love,And be careful of what you do'Cause the lie becomes the truth.\"Billie Jean is not my loverShe's just a girl who claims that I am the oneBut the kid is not my sonShe says I am the oneBut the kid is not my sonFor forty days and for forty nightsLaw was on her sideBut who can standWhen she's in demandHer schemes and plans'Cause we danced on the floor in the roundSo take my strong adviceJust remember to always think twice(Do think twice, do think twice.)She told, \"My baby, we'd danced 'til three.\"Then she looked at meThen showed a photo of a baby cryHis eyes looked like mine, oh, noDo a dance on the floor in the round, babyA-people always told me, \"Be careful of what you doAnd don't go around breaking young girls' hearts.\"(Don't break no heart.)A-but she came and stood right by meAnd just the smell of sweet perfumeAnd this happened much too soonAnd she called me to her roomBillie Jean is not my loverShe's just a girl who claims that I am the oneBut the kid is not my son(No, no, no, no, no, no, no, no.)Billie Jean is not my loverShe's just a girl who claims that I am the oneBut the kid is not my sonShe says I am the oneBut the kid is not my sonShe says I am the oneBut the kid is not my sonNo, no, noBillie Jean is not my loverShe's just a girl who claims that I am the one(No, there's not me, baby.)But the kid is not my son(No, no, no, no, no, no, no.)She says I am the one (No, babe.)But the kid is not my son, no, no, noShe says I am the oneYou know what you didShe says he is my sonBreaking my heart, babeShe says I am the oneBillie Jean is not my loverBillie Jean is not my loverBillie Jean is not my loverShe is the oneBillie Jean is not my loverShe is the oneDon't call me Billie JeanShe is the oneBillie Jean is not my loverShe is the oneBillie Jean is not my lover\n",
            "I searched the worldBut it couldn't fill meMan's empty praiseAnd treasures that fadeAre never enoughThen You came alongAnd put me back togetherAnd every desireIs now satisfiedHere in Your loveOh there's nothing better than YouThere's nothing better than YouLord there's nothingNothing is better than YouI'm not afraidTo show You my weaknessMy failures and flawsLord You've seen 'em allAnd You still call me friend'Cause the God of the mountainIs the God of the valleyThere's not a placeYour mercy and graceWon't find me againOh there's nothing better than YouThere's nothing better than YouLord, there's nothingNothing is better than YouOh, there's nothing better than YouThere's nothing better than YouLord there's nothingNothing is better than YouYou turn mourning to dancingYou give beauty for ashesYou turn shame into gloryYou're the only one who canYou turn mourning to dancingYou give beauty for ashesYou turn shame into gloryYou're the only one who canYou turn graves into gardenYou turn bones into armiesYou turn seas into highwaysYou're the only one who canYou're the only one who canYou're the only one who canOh, there's nothing better than YouThere's nothing better than YouLord, there's nothingNothing is better than YouOh, there's nothing better than YouThere's nothing better than YouLord, there's nothingNothing is better than YouYou turn graves into gardensYou turn bones into armiesYou turn seas into highwaysYou're the only one who canYou're the only one who canYou're the only one who can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_def(Christian_inline)\n",
        "genre_def(Pop_inline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgZQ0RbM1Mu",
        "outputId": "5b679b5e-1293-4eb2-8108-0db3e9cc5782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Christian']\n",
            "['Pop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Задание 3***"
      ],
      "metadata": {
        "id": "h9AUUgjouZiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import of csv\n",
        "dataset_lyrics = pd.read_csv(\"dataset-lyrics-musics-mini.csv\")\n",
        "columns = dataset_lyrics[['cantorNome', 'letra']]\n",
        "columns = columns[(columns.cantorNome == 'paul-mccartney') | (columns.cantorNome == 'david-bowie')]"
      ],
      "metadata": {
        "id": "F0-elQUPuk24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dropped other names\n",
        "tokenized =[]\n",
        "for a in columns[\"letra\"]:\n",
        "  tokenized.append(go2token(a))\n",
        "columns[\"letra\"] = tokenized\n",
        "print(columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGKQlLFeuszK",
        "outputId": "7630c40d-0ad4-46a3-922f-67fea0d4c263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         cantorNome                                              letra\n",
            "0       david-bowie  I, I, king, And, queen, Though, nothing, drive...\n",
            "1       david-bowie  Did, n't, know, time, The, light, low, I, lean...\n",
            "2       david-bowie  Ground, control, Major, Tom, Ground, control, ...\n",
            "3       david-bowie  It, 's, god-awful, small, affair, To, girl, mo...\n",
            "4       david-bowie  I, know, go, And, stay, Get, thing, done, I, c...\n",
            "..              ...                                                ...\n",
            "942  paul-mccartney  He, 's, young, boy, looking, way, find, love, ...\n",
            "943  paul-mccartney  How, I, hope, reach, love, Help, discover, Wha...\n",
            "944  paul-mccartney  I, like, Please, n't, take, heart, away, It, '...\n",
            "945  paul-mccartney  Yvonne, one, I´ve, counting, She, said, long, ...\n",
            "946  paul-mccartney                                       Instrumental\n",
            "\n",
            "[947 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(columns.letra, columns.cantorNome, train_size = 0.7)\n",
        "columns.cantorNome.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-UMrStpu1Wy",
        "outputId": "9dd6dd03-a338-454b-abf1-b6b224ebd4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "david-bowie       483\n",
              "paul-mccartney    464\n",
              "Name: cantorNome, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Vectorization and learning etc\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)\n",
        "vectorized_x_test = vectorizer.transform(x_test)\n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krwxmfLIvXQY",
        "outputId": "2ba16934-e22a-4855-e519-b86a7025463b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "   david-bowie       0.75      0.76      0.76       146\n",
            "paul-mccartney       0.74      0.73      0.74       139\n",
            "\n",
            "      accuracy                           0.75       285\n",
            "     macro avg       0.75      0.75      0.75       285\n",
            "  weighted avg       0.75      0.75      0.75       285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Finish***"
      ],
      "metadata": {
        "id": "svlNyqKbvkV_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Atec9Uy_CYJ"
      },
      "source": [
        "1) Запустить ячейку ниже, чтобы получить 2 жанра. Для полученных жанров провести все этапы предварительной обработки текста (как в примере), обучить наивный байесовский классификатор, численно оценить его работу."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxkZ901zyLPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4246c3-d14e-430a-c1a7-1d0c5fbf1a30"
      },
      "source": [
        " import random \n",
        " lst = ['Christian', 'Country', 'Pop', 'Rock', 'R&B'] \n",
        " print('ваши жанры', random.choice(lst), 'и', random.choice(lst)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ваши жанры Pop и Christian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNAI2TMBxMDH"
      },
      "source": [
        "Для улучшения качества обучения модели можно попробовать избавиться от знаков препинания и проследить, чтобы процентное соотношение песен обоих жанров было примерно 50 на 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWdnLBHf_onv"
      },
      "source": [
        "2) Найти (нагуглить) по песне каждого из жанров, которые Вам достались, после необходимой обработки их текстов определить жанр обеих песен с помощью обученной в ходе выполнения предыдущего пункта модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtmpuwX6AZy6"
      },
      "source": [
        "3) С помощью набора данных по ссылке аналогичным образом научить модель отличать тексты песен Дэвида Боуи от текстов песен Пола МакКартни \n",
        "https://www.kaggle.com/italomarcelo/dataset-lyrics-music-mini"
      ]
    }
  ]
}